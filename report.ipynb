{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Machine learning and Neural Ne\n",
    "## Prepared by Karol WesoÅ‚owski, L2, 148116"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9348f3489fee022"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Task"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62bf9ed088fb1efa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The task was to implement a simple decision tree generating algorith, including calculating gain and other values. The code was prepared in python using pandas. Graphs created using NetworkX. Report designed in Jupyter Notebook. Code uses several global structures to represent generated tree and to allow the tree to be properly shown in graphic form. `const_box` defines the size of nodes on the graph. `counter` is used to enumerate the nodes. Other structures are self-explanatory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "149c74b5fbe6144c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "const_box = 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35134663b97e264"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d71d65102adf333"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data used in this task is a well known dataset called Titanic representing passengers of the ship and they're status after the catastrophy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d904dd128f76fcf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/titanic-homework.csv\", index_col=\"PassengerId\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data consist of several columns. `PassengerId` is treated as Dataframe identifier (index). `Name` is omitted in the calculations, since it does not provide any valuable data. `Pclass`, `Sex`, `SibSp` and `Parch` are discrete values and are used as attributes for decisions. `Age` is a continuous value and as such has to be mapped to discrete. `Survived` is the result of calculation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7c1cbb37b3ed144"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mapper(data: pd.DataFrame):\n",
    "    data['Age'] = data.apply(lambda row: (\n",
    "        \"old\" if row[\"Age\"] > 40 else (\"medium\" if row[\"Age\"] > 20 else \"young\")), axis=1)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d837c51d10d7bab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function `mapper` takes DataFrame as input and performs a mapping on column `Age` changing all values higher than 40 to label *old*, those between 40 (icl.) and 20 (excl.) - to *medium* and lower or equal to 20 to *young*. \n",
    "Every preparation is done in the function `prepare_data`. Additionally, the functions extracts the outcome column and saves it as np.Series:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41b57e0f7f6264e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    data = pd.read_csv(\"data/titanic-homework.csv\", index_col=\"PassengerId\")\n",
    "    outcome = data['Survived']\n",
    "    outcome.name = \"outcome\"\n",
    "    data = data.drop(['Name', 'Survived'], axis='columns')\n",
    "    data = mapper(data)\n",
    "    return data, outcome"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d0cbf789cd48eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepared data looks as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dcf9401cb86bcd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data, outcome = prepare_data()\n",
    "print(\"data\")\n",
    "print(data.head())\n",
    "print(\"outcome\")\n",
    "print(outcome.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ee1da71c3e18cf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "270074a4ae8e43ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To build a decision tree it is necessary to choose the best branch. It can be done using a value called entropy. This value defines how much various information is in one message (block of data). If entropy is equal to 0, it means that the block is pure and contains only one type of data. Entropy on one column is defined as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b1fa3881d34f2d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def single_entropy(value: int, size: int):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    return -1 * (value / size) * math.log2((value / size))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2076123faf44cfff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`entropy` function uses the above function to calculate the entropy on the given column. It performs necessary preparations (concatenating tables, selecting only the interesting columns, grouping them by value) and returns entropy of the attribute as well as cleaned data. The results can be seen below."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e4892ba8b94f71b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def entropy(data: pd.DataFrame, outcome: pd.Series, column: str):\n",
    "    used_data = data[column]\n",
    "    used_data.name = column\n",
    "    size = used_data.size\n",
    "    used_data = pd.concat([used_data, outcome], axis=1)\n",
    "    positives = used_data.groupby(column)['outcome'].sum()\n",
    "    counts = used_data.groupby(column)['outcome'].count()\n",
    "    used_data = pd.concat([positives, counts], axis=1)\n",
    "    used_data.columns = ['positives', 'count']\n",
    "    used_data['entropy'] = used_data.apply(lambda row: single_entropy(row['positives'], size), axis=1)\n",
    "    return used_data['entropy'].sum(), used_data\n",
    "\n",
    "\n",
    "for col in data.columns:\n",
    "    ent, aggr = entropy(data, outcome, col)\n",
    "    print(f\"Entropy: {col}: {ent}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39d7f4a10f9c53a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entropy output on the first level: \n",
    "Entropy: Pclass: 1.1571514757368124\n",
    "Entropy: Sex: 0.7963775719775679\n",
    "Entropy: Age: 1.1208917147235118\n",
    "Entropy: SibSp: 1.04638292837967\n",
    "Entropy: Parch: 1.0136302372796246\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38a08ab4f277e143"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the calculated values, the program has to perform next operations to get information gain. For that it uses so-called **conditional entropy** (entropy multiplied by the probability of occurrence of value in the dataset). The gain is calculated as the difference between entropy on a branch and conditional entropy on that branch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa588e2f64c89ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conditional_entropy(data: pd.DataFrame):\n",
    "    data[\"cond_ent\"] = data.apply(lambda row: row[\"positives\"] / row['count'] * row['entropy'], axis=1)\n",
    "    return data['cond_ent'].sum(), data\n",
    "\n",
    "for col in data.columns:\n",
    "    ent, aggr = entropy(data, outcome, col)\n",
    "    cond, aggr = conditional_entropy(aggr)\n",
    "    gain = ent - cond\n",
    "    print(f\"Gain: {col}: {gain}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e109ec8ad633ff0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, gain is sufficient for constructing trees. But in some dataset it may be needed to calculate also ** intrinsic gain **. That value is the used to divide the gain and normalises it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65989309e12f2ecf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intrinsic(data: pd.DataFrame):\n",
    "    data['intr'] = data.apply(lambda row: single_entropy(row['positives'], row['count']), axis=1)\n",
    "    return data['intr'].sum(), data\n",
    "\n",
    "for col in data.columns:\n",
    "    ent, aggr = entropy(data, outcome, col)\n",
    "    cond, aggr = conditional_entropy(aggr)\n",
    "    gain = ent - cond\n",
    "    intr, aggr = intrinsic(aggr)\n",
    "    if intr != 0:\n",
    "        ratio = gain / intr\n",
    "    else:\n",
    "        ratio = 0\n",
    "    print(f\"Ratio: {col}: {ratio}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50247a1a38bd8108"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gain ration on the first level:\n",
    "Ratio: Pclass: 0.43409021347716104\n",
    "Ratio: Sex: 0.5580847615421273\n",
    "Ratio: Age: 0.42572837608378944\n",
    "Ratio: SibSp: 0.2910303997343847\n",
    "Ratio: Parch: 0.281110416720371\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46c785408f256f64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This set of instructions is used to choose the attribute, that will create the purest data after the division. This choice is performed using `best_branch` function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baa87fc0d35d0a98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def best_branch(data, outcome):\n",
    "    results = {}\n",
    "    for col in data.columns:\n",
    "        ent, aggr = entropy(data, outcome, col)\n",
    "        cond, aggr = conditional_entropy(aggr)\n",
    "        gain = ent - cond\n",
    "        intr, aggr = intrinsic(aggr)\n",
    "        if intr != 0:\n",
    "            ratio = gain / intr\n",
    "        else:\n",
    "            ratio = 0\n",
    "        results[col] = ratio\n",
    "    results = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "    results.columns = [\"ratio\"]\n",
    "    results = results.sort_values(\"ratio\", ascending=False)\n",
    "    return results.head(1).index.values[0]\n",
    "\n",
    "print(f\"Best branch in current state: {best_branch(data, outcome)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a430f21fc57ebeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dcb68c8d3acb69f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The tree is generated recursively repeating the best branch choice and dividing data based on that choice. The calculation is finished, when the achieved data is pure, i.e. contains only outcome belonging to one category. To check for purity program uses the so called function. This function takes the selected column, split data based on the values in this attribute and counts if the category in outcome applies for every row. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "710753ec3d9ba7d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def purity_check(data, outcome, col):\n",
    "    used_data = data[col]\n",
    "    used_data.name = col\n",
    "    used_data = pd.concat([used_data, outcome], axis=1)\n",
    "    positives = used_data.groupby(col)['outcome'].sum()\n",
    "    counts = used_data.groupby(col)['outcome'].count()\n",
    "    used_data = pd.concat([positives, counts], axis=1)\n",
    "    used_data.columns = ['positives', 'count']\n",
    "    used_data['pure'] = used_data.apply(lambda row: row['positives'] == row['count'] or row['positives'] == 0, axis=1)\n",
    "    purity = used_data['pure'].sum() == used_data.shape[0]\n",
    "    return purity, used_data\n",
    "\n",
    "best = best_branch(data, outcome)\n",
    "purity, res = purity_check(data, outcome, best)\n",
    "print(f\"purity: {purity}\")\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d513d994fa3ca39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `build_tree` is recursive and takes three arguments:\n",
    "1. data\n",
    "2. outcome\n",
    "3. depth - current level of the tree, used to present the result.\n",
    "In each iteration the function finds the best branch and calculates the purity on it. Then, for every category in the selected attribute, it checks, if it contains pure data. If so, decision is printed and the execution returns. Otherwise, the data is prepared for the new iteration. Selected are only rows with fitting category, currently processed column is dropped. The execution is resumed on the new level.\n",
    "4. Result is presented in the text form, with indentation indicating the level of the tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576500d55404c06e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_tree(data, outcome, depth=0):\n",
    "    best = best_branch(data, outcome)\n",
    "    purity, res = purity_check(data, outcome, best)\n",
    "    \n",
    "    for row in res.iterrows():\n",
    "        print(depth * '\\t' + best + ' - ' + str(row[0]) + ': ')\n",
    "        if not row[1]['pure']:\n",
    "            new_data = data[data[best] == row[0]]\n",
    "            new_data = new_data.drop(best, axis='columns')\n",
    "            new_out = outcome[new_data.index]\n",
    "            build_tree(new_data, new_out, depth + 1)\n",
    "        else:\n",
    "            print((depth + 1) * '\\t' + f\"decision:{1 if row[1]['positives'] > 0 else 0}\")\n",
    "    return\n",
    "\n",
    "build_tree(data, outcome)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5227ab1b7a9831b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Visualisation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69beb244b4ee70c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Packet NetworkX is used to convert text output into graphical one. The main visualisation function looks as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "217d1404446ea872"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_pos():\n",
    "    pos = {}\n",
    "    max_x = 2*const_box * (len(flat)+1)\n",
    "    for i, row in enumerate(flat):\n",
    "        y = const_box * (len(flat)+1 - i)\n",
    "        step = max_x / len(row)\n",
    "        x = step/2\n",
    "        for node in row:\n",
    "            pos[node] = (x, y)\n",
    "            x += step\n",
    "    return pos\n",
    "\n",
    "def visualise(title: str = \"graph\"):\n",
    "    plt.figure(figsize=(2*(len(flat)), 2*(len(flat))))\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    pos = calculate_pos()\n",
    "    nx.draw_networkx(G, pos=pos, labels=labels, arrows=True,\n",
    "                     bbox=dict(facecolor=\"skyblue\",\n",
    "                               boxstyle=\"round\", pad=0.3),\n",
    "                     edge_color=\"gray\")\n",
    "    nx.draw_networkx_edge_labels(G, pos=pos,\n",
    "                                 edge_labels=edges_l,\n",
    "                                 font_color='black')\n",
    "    plt.title(title)\n",
    "    plt.savefig(title + '.png', dpi=300)\n",
    "    plt.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb9d1ebfc543cb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`calculate_pos` is used to determine positions of nodes on the printout. To visualise the tree, function need following structures:\n",
    "- list of all nodes (as numbers)\n",
    "- list of all edges (as a pair of number from above list)\n",
    "- list of positions (pair of numbers, calculated above)\n",
    "- dictionary of node labels (int:str)\n",
    "- dictionary of edge labels (pair(int, int):str)\n",
    "Flat is an additional structure, representing the tree as a list of lists of nodes used to calculate positions. \n",
    "To obtain all the information, the `build_tree` function has to be modified in the following way:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed3cfef76d5afca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_tree(data, outcome, depth=0, parent=-1, desc=\"\"):\n",
    "    global nodes, flat, edges, counter, labels\n",
    "    best = best_branch(data, outcome)\n",
    "    purity, res = purity_check(data, outcome, best)\n",
    "    while len(flat) <= depth + 1:\n",
    "        flat.append([])\n",
    "    nodes.append(counter)\n",
    "    flat[depth].append(counter)\n",
    "    labels[counter] = best\n",
    "    if parent != -1:\n",
    "        edges.append((parent, counter))\n",
    "        edges_l[(parent, counter)] = desc\n",
    "    current = counter\n",
    "    counter += 1\n",
    "\n",
    "    for row in res.iterrows():\n",
    "        desc = str(row[0])\n",
    "        if not row[1]['pure']:\n",
    "            new_data = data[data[best] == row[0]]\n",
    "            new_data = new_data.drop(best, axis='columns')\n",
    "            new_out = outcome[new_data.index]\n",
    "            build_tree(new_data, new_out, depth + 1, current, desc)\n",
    "        else:\n",
    "            decision = 1 if row[1]['positives'] > 0 else 0\n",
    "            nodes.append(counter)\n",
    "            labels[counter] = decision\n",
    "            edges.append((current, counter))\n",
    "            edges_l[(current, counter)] = desc\n",
    "            flat[depth + 1].append(counter)\n",
    "            counter += 1\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26c02eea0fbeaba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "That concludes the execution. The functions have to be called in following order. The graph is saved to .png file with the same name as the title of the graph, provided as the argument ('graph.png' by default)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d355276121a958c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flat = []\n",
    "edges = []\n",
    "nodes = []\n",
    "labels = {}\n",
    "edges_l = {}\n",
    "counter = 0\n",
    "\n",
    "data, outcome = prepare_data()\n",
    "build_tree(data, outcome)\n",
    "visualise(\"Decision tree visualisation for Titanic dataset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eb93bddaad8f348"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Visualisation](graph.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd20f7b393d690c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Summary\n",
    "The output is clear and easily readable. It may be used to determine the outputs of newcomming data. One of the improvements may be taking the continuous value as it is, and performing additional set of operations on it. It may lead to change of the results, but would require more work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85bdf058abe21ea"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def cont_mapper(data: pd.DataFrame, out: pd.Series, col: str, min_group:int=2):\n",
    "    results = {}\n",
    "    u_data = data[col]\n",
    "    s = u_data.size\n",
    "    data.name = col\n",
    "    u_data = pd.concat([u_data, out], axis=1)\n",
    "    u_data = u_data.sort_values(col)\n",
    "    \n",
    "    last = u_data[\"outcome\"].iloc[0]\n",
    "    for i in range (min_group, s-min_group):\n",
    "        if u_data[\"outcome\"].iloc[i] != last:\n",
    "            last = u_data[\"outcome\"].iloc[i]\n",
    "            upper = u_data.head(i+1)\n",
    "            upper_stat = (upper[\"outcome\"].sum())/(i+1)\n",
    "            lower = u_data.tail(s - 1 - i)\n",
    "            lower_stat = (lower[\"outcome\"].sum())/(s - 1 - i)\n",
    "            entry = [upper_stat, 1-upper_stat, lower_stat, 1-lower_stat]\n",
    "            results[i] = entry\n",
    "    ans = pd.DataFrame.from_dict(results, \"index\")\n",
    "    ans.columns = [\"up\", \"neg_up\", \"low\", \"neg_low\"]\n",
    "    maks = (ans.max().idxmax(), ans[ans.max().idxmax()].idxmax())\n",
    "    cut_age = u_data[\"Age\"].iloc[maks[1]] - 0.5\n",
    "    data['new_age'] = data.apply(lambda row: (\n",
    "        \"one\" if row[\"Age\"] < cut_age else \"two\"), axis=1)\n",
    "    return data\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:37:21.738050Z",
     "start_time": "2023-10-23T13:37:21.717307300Z"
    }
   },
   "id": "dd049f4524ba73f4"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg_low', 95)\n",
      "64.5\n",
      "             Pclass     Sex  Age  SibSp  Parch new_age\n",
      "PassengerId                                           \n",
      "65                1    male   57      0      0     one\n",
      "12                1  female   58      0      0     one\n",
      "95                3    male   59      0      0     one\n",
      "20                3  female   63      0      0     one\n",
      "33                3  female   63      0      0     one\n",
      "55                1    male   65      0      1     two\n",
      "34                2    male   66      0      0     two\n",
      "97                1    male   71      0      0     two\n",
      "32                1  female   77      1      0     two\n",
      "30                3    male   78      0      0     two\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/titanic-homework.csv\", index_col=\"PassengerId\")\n",
    "outcome = data['Survived']\n",
    "outcome.name = \"outcome\"\n",
    "data = data.drop(['Name', 'Survived'], axis='columns')\n",
    "data = cont_mapper(data, outcome, \"Age\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T13:37:22.076262600Z",
     "start_time": "2023-10-23T13:37:22.053889700Z"
    }
   },
   "id": "649f7afc5102d6e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "750de153540f5721"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
